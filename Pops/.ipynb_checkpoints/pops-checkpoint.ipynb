{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05699a8b-a4c7-4525-99f3-f07e538faa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pops'...\n",
      "remote: Enumerating objects: 235, done.\u001b[K\n",
      "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
      "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
      "remote: Total 235 (delta 26), reused 23 (delta 12), pack-reused 196\u001b[K\n",
      "Receiving objects: 100% (235/235), 108.46 MiB | 15.10 MiB/s, done.\n",
      "Resolving deltas: 100% (103/103), done.\n",
      "Updating files: 100% (25/25), done.\n",
      "/Users/JerryYaw/Documents/TWAS/Pops/pops\n",
      "/Users/JerryYaw/Documents/TWAS/Pops/pops\n"
     ]
    }
   ],
   "source": [
    "# Download pops github repo\n",
    "!git clone https://github.com/FinucaneLab/pops.git\n",
    "\n",
    "# Copy pops.ipynb to pops folder\n",
    "!cp pops.ipynb pops/\n",
    "\n",
    "# Change directory to pops and make sure we are now in \"TWAS/Pops/pops\"\n",
    "%cd pops/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea97e22-0a5e-401b-b74d-f5efe9e30feb",
   "metadata": {},
   "source": [
    "# Environment Setup\n",
    "Please download the **pops pipeline data**, **magma software** and **gene features** to the current pops folder.<br>\n",
    "And arrange the feature folders according to the Tips below<br>\n",
    "\n",
    "<h3>Download PoPS Pipeline Data</h3>\n",
    "<pre><code>Please choose the gene prioritization results to download and save as data in pops.\n",
    "<a href=\"https://www.finucanelab.org/data\">Finucane Lab Data</a>\n",
    "</code></pre>\n",
    "\n",
    "<h3>Download Magma software</h3>\n",
    "<pre><code>Please find the compiler and operation system that suits you, and unzip to the pops folder!\n",
    "<a href=\"https://cncr.nl/research/magma/\">CNCR CTG Lab Magma</a>\n",
    "</code></pre>\n",
    "\n",
    "<h3>Download Gene Features</h3>\n",
    "<pre><code>We use human_lung and human_pbmc for COVID19 pops pipeline \n",
    "<a href=\"https://github.com/FinucaneLab/gene_features/tree/master/features\">Finucane Lab Features</a>\n",
    "</code></pre>\n",
    "\n",
    "<div style=\"background-color: #ADD8E6; color: black; border-left: 5px solid black; padding: 10px;\">\n",
    "    <b>Tip:</b> Please refer to the pops example's data folder and arrange human_lung and human_pbmc similarly. This means you can create human_lung and humna_pmbc folders under the data folder and copy four folders (features_munged,features_raw,magma_scores, and utils) from the example data for each, replacing the files in features_raw with the download features(keep GTEx.txt). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd20371e-ac52-4618-a1f5-d4fc6cd7cf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading COVID19_HGI_A1_ALL_20201020.txt.gz...\n",
      "Downloading COVID19_HGI_A2_ALL_leave_23andme_20201020.txt.gz...\n",
      "Downloading COVID19_HGI_B2_ALL_leave_23andme_20201020.txt.gz...\n",
      "Downloading COVID19_HGI_B1_ALL_20201020.txt.gz...\n",
      "Unzipping COVID19_HGI_B2_ALL_leave_23andme_20201020.txt.gz...\n",
      "Unzipping COVID19_HGI_A1_ALL_20201020.txt.gz...\n",
      "Unzipping COVID19_HGI_A2_ALL_leave_23andme_20201020.txt.gz...\n",
      "Completed COVID19_HGI_A1_ALL_20201020.txt.gz.\n",
      "Downloading COVID19_HGI_C1_ALL_leave_23andme_20201020.txt.gz...\n",
      "Completed COVID19_HGI_B2_ALL_leave_23andme_20201020.txt.gz.\n",
      "Downloading COVID19_HGI_C2_ALL_leave_23andme_20201020.txt.gz...\n",
      "Unzipping COVID19_HGI_B1_ALL_20201020.txt.gz...\n",
      "Completed COVID19_HGI_A2_ALL_leave_23andme_20201020.txt.gz.\n",
      "Downloading COVID19_HGI_D1_ALL_20201020.txt.gz...\n",
      "Unzipping COVID19_HGI_C1_ALL_leave_23andme_20201020.txt.gz...\n",
      "Completed COVID19_HGI_B1_ALL_20201020.txt.gz.\n",
      "Unzipping COVID19_HGI_D1_ALL_20201020.txt.gz...\n",
      "Unzipping COVID19_HGI_C2_ALL_leave_23andme_20201020.txt.gz...\n",
      "Completed COVID19_HGI_C1_ALL_leave_23andme_20201020.txt.gz.\n",
      "Completed COVID19_HGI_D1_ALL_20201020.txt.gz.\n",
      "Completed COVID19_HGI_C2_ALL_leave_23andme_20201020.txt.gz.\n",
      "All files downloaded, unzipped, and combined.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "import shutil\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Download and preprocessing COVID19 GWAS Summary data\n",
    "download_dir = \"data_covid\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "urls = [\n",
    "    \"https://storage.googleapis.com/covid19-hg-public/20200915/results/20201020/COVID19_HGI_A1_ALL_20201020.txt.gz\",\n",
    "    \"https://storage.googleapis.com/covid19-hg-public/20200915/results/20201020/COVID19_HGI_A2_ALL_leave_23andme_20201020.txt.gz\",\n",
    "    \"https://storage.googleapis.com/covid19-hg-public/20200915/results/20201020/COVID19_HGI_B1_ALL_20201020.txt.gz\",\n",
    "    \"https://storage.googleapis.com/covid19-hg-public/20200915/results/20201020/COVID19_HGI_B2_ALL_leave_23andme_20201020.txt.gz\",\n",
    "    \"https://storage.googleapis.com/covid19-hg-public/20200915/results/20201020/COVID19_HGI_C1_ALL_leave_23andme_20201020.txt.gz\",\n",
    "    \"https://storage.googleapis.com/covid19-hg-public/20200915/results/20201020/COVID19_HGI_C2_ALL_leave_23andme_20201020.txt.gz\",\n",
    "    \"https://storage.googleapis.com/covid19-hg-public/20200915/results/20201020/COVID19_HGI_D1_ALL_20201020.txt.gz\",\n",
    "]\n",
    "\n",
    "def download_and_unzip(url):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    dest_path = os.path.join(download_dir, local_filename)\n",
    "    txt_filename = local_filename.rstrip('.gz')\n",
    "    txt_path = os.path.join(download_dir, txt_filename)\n",
    "\n",
    "    if not os.path.exists(dest_path):\n",
    "        print(f\"Downloading {local_filename}...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()  # Check for errors\n",
    "        with open(dest_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "    print(f\"Unzipping {local_filename}...\")\n",
    "    with gzip.open(dest_path, 'rb') as f_in:\n",
    "        with open(txt_path, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    os.remove(dest_path)  # Remove all .gz files\n",
    "    print(f\"Completed {local_filename}.\")\n",
    "\n",
    "# Download and unzip files in parallel\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    executor.map(download_and_unzip, urls)\n",
    "\n",
    "# Merge all COVID19 GWAS summary files into one\n",
    "summary_stats_path = os.path.join(download_dir, \"COVID19_GWAS_summary_stats.txt\")\n",
    "\n",
    "# Sort the files Before merging\n",
    "txt_files = [f for f in os.listdir(download_dir) if f.endswith(\".txt\")]\n",
    "txt_files.sort()\n",
    "\n",
    "with open(summary_stats_path, 'wb') as outfile:\n",
    "    for i, filename in enumerate(txt_files):\n",
    "        file_path = os.path.join(download_dir, filename)\n",
    "        with open(file_path, 'rb') as readfile:\n",
    "            # Skip the header for all but the first file\n",
    "            if i != 0:\n",
    "                next(readfile)  # Skip the first line (header) of subsequent files\n",
    "            shutil.copyfileobj(readfile, outfile)\n",
    "\n",
    "# Remove all .txt files \n",
    "for filename in txt_files:\n",
    "    if filename != os.path.basename(summary_stats_path):\n",
    "        os.remove(os.path.join(download_dir, filename))\n",
    "\n",
    "print(\"All files downloaded, unzipped, and combined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e186609a-111d-4d40-a6e6-b4cdbd77fe85",
   "metadata": {},
   "source": [
    "# hg38 reference panel (optional)\n",
    "The PoPS Pipeline Data includes a reference panel of 1000G.EUR European genome data. If you want to use hg38 instead, please download the Plink 2.0 software and move its executable file \"plink2.0\" to the pops folder so the following script can run.\n",
    "<h3>Download Plink</h3>\n",
    "Please choose the operation system and version that suits you, and unzip it to the pops folder!\n",
    "<pre><code>\n",
    "<a href=\"https://www.cog-genomics.org/plink/2.0/\">Christopher Chang Plink</a>\n",
    "</code></pre>\n",
    "\n",
    "<div style=\"background-color: pink; color: black; border-left: 5px solid black; padding: 10px;\">\n",
    "    <b>Tip:</b> The common system path in Mac is \"/usr/local/bin/\" or \"~/bin/\" After placing the executed file, you can use plink or plink --version to check if the installation succeeded.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a79d6822-e36f-4cd3-bd50-b4bb4e11de70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data files...\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    62    0    62    0     0    170      0 --:--:-- --:--:-- --:--:--   170\n",
      "100   320  100   320    0     0    380      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 3239M  100 3239M    0     0  64.9M      0  0:00:49  0:00:49 --:--:-- 69.4M   0  0:00:59  0:00:08  0:00:51 68.0M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   240    0   240    0     0    369      0 --:--:-- --:--:-- --:--:--   369\n",
      "100   475    0   475    0     0    398      0 --:--:--  0:00:01 --:--:--   398\n",
      "100 2748M  100 2748M    0     0  46.4M      0  0:00:59  0:00:59 --:--:-- 45.9M5.2M      0  0:01:17  0:00:07  0:01:10 47.7M0  46.4M      0  0:00:59  0:00:58  0:00:01 46.0M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    64    0    64    0     0    141      0 --:--:-- --:--:-- --:--:--   141\n",
      "100   320  100   320    0     0    299      0  0:00:01  0:00:01 --:--:--   299\n",
      "100 77819  100 77819    0     0  55496      0  0:00:01  0:00:01 --:--:-- 1688k\n",
      "Decompressing data files...\n",
      "all_hg38.pgen.zst   : 9530881334 bytes                                         \n",
      "all_hg38.pvar.zst   : 81466544634 bytes                                        \n",
      "Converting to PLINK binary format...\n",
      "PLINK v2.00a6 64-bit (18 Mar 2024)             www.cog-genomics.org/plink/2.0/\n",
      "(C) 2005-2024 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to data/all_hg38.log.\n",
      "Options in effect:\n",
      "  --make-bed\n",
      "  --max-alleles 2\n",
      "  --out data/all_hg38\n",
      "  --pfile all_hg38\n",
      "\n",
      "Start time: Mon Apr  8 09:15:21 2024\n",
      "16384 MiB RAM detected; reserving 8192 MiB for main workspace.\n",
      "Using up to 8 compute threads.\n",
      "3202 samples (1603 females, 1599 males; 2583 founders) loaded from\n",
      "all_hg38.psam.\n",
      "Note: 2585 nonstandard chromosome codes present.\n",
      "74929081 out of 75193455 variants loaded from all_hg38.pvar.\n",
      "2 categorical phenotypes loaded.\n",
      "74929081 variants remaining after main filters.\n",
      "Writing data/all_hg38.fam ... done.\n",
      "Writing data/all_hg38.bim ... done.\n",
      "Writing data/all_hg38.bed ... 101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899done.\n",
      "End time: Mon Apr  8 09:19:43 2024\n",
      "Plink binary conversion finish\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Create hg38 reference panel(optional)\n",
    "!cp ../getRefHg38.sh .\n",
    "!yes | bash getRefHg38.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76075cbd-dcee-4a84-979a-b7b772c5ed0a",
   "metadata": {},
   "source": [
    "# Add codes to solve a common problem before running \n",
    "The \"ValueError: shapes (18383,743) and (1867) not aligned: 743 (dim 1) != 1867 (dim 0)\" issue is caused by the duplicated name in the generated matrix table. A **solution provided by Vinodsri** in the GitHub issue is adding codes renaming the feature clusters in the **munge_feature_directory.py** script.\n",
    "\n",
    "<h3>Insert the code chunk in the position and import os</h3>\n",
    "<pre><code>\n",
    "import os\n",
    "    \n",
    "for f in all_feature_files:\n",
    "    f_df = pd.read_csv(f, sep=\"\\t\", index_col=0).astype(np.float64)\n",
    "    f_df = gene_annot_df.merge(\n",
    "        f_df, how=\"left\", left_index=True, right_index=True)\n",
    "    <span style=\"color: brown;\"># Add the following three line codes accordingly to munge_feature_directory.py</span>\n",
    "    base_filename = os.path.basename(f)\n",
    "    fname = base_filename.replace(r\".txt.gz\", \"_\")\n",
    "    f_df.columns = f_df.columns.str.replace(r\"Cluster\", fname)\n",
    "    <span style=\"color: brown;\"># -----------------------------  by vinodhsri  ------------------------------</span>\n",
    "    if nan_policy == \"raise\":\n",
    "        assert not f_df.isnull().values.any(), \"Missing genes in feature matrix.\"\n",
    "</code></pre>\n",
    "\n",
    "<h3>Now, that's start the pops pipelines with hg38 reference panel! </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82e23ddd-eee0-4cbb-961a-dc7490508ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process feature files to feature matrix file...\n",
      "Feature matrix process completed\n"
     ]
    }
   ],
   "source": [
    "# Calling Pops0 step \n",
    "!cp ../runPopsi0.sh .\n",
    "!bash runPopsi0.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff976ccf-8da2-426d-a762-341ef7d717b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate magma score for each GWAS summary statistic file...\n",
      "Welcome to MAGMA v1.10 (custom)\n",
      "Using flags:\n",
      "\t--bfile data/all_hg38\n",
      "\t--gene-annot data/magma_0kb.genes.annot\n",
      "\t--pval data_covid/COVID19_GWAS_summary_stats.txt use=13,9 ncol=11\n",
      "\t--gene-model snp-wise=mean\n",
      "\t--out data/human_lung/magma_scores/lung-COVID19\n",
      "\n",
      "Start time is 10:18:00, Monday 08 Apr 2024\n",
      "\n",
      "Loading PLINK-format data...\n",
      "Reading file data/all_hg38.fam... 3202 individuals read\n",
      "Reading file data/all_hg38.bim... 70883903 SNPs read\n",
      "\tWARNING: file contains 1868379 duplicate SNP IDs; writing list of IDs to supplementary log file\n",
      "Preparing file data/all_hg38.bed... \n",
      "\n",
      "Reading SNP p-values from file data_covid/COVID19_GWAS_summary_stats.txt... \n",
      "\tdetected 13 variables in file\n",
      "\tusing variable: variable 13 (SNP id)\n",
      "\tusing variable: variable 9 (p-value)\n",
      "\tusing variable: variable 11 (sample size; discarding SNPs with N < 50)\n",
      "\tread 84817347 lines from file, containing valid SNP p-values for 2588143 SNPs in data (3.051% of lines, 3.454% of SNPs in data)\n",
      "\tWARNING: file contained 10806072 SNP IDs with duplications\n",
      "\t         dropped all occurrences of each from analysis\n",
      "\t         writing list of duplicated IDs to supplementary log file\n",
      "Loading gene annotation from file data/magma_0kb.genes.annot... \n",
      "\t18223 gene definitions read from file\n",
      "\tfound 9731 genes containing valid SNPs in genotype data\n",
      "\n",
      "\n",
      "Starting gene analysis... \n",
      "\tusing model: SNPwise-mean\n",
      "\tWARNING: analysis failed for gene ENSG00000185940; gene contains no valid SNPs after internal QC\n",
      "\twriting gene analysis results to file data/human_lung/magma_scores/lung-COVID19.genes.out                         \n",
      "\twriting intermediate output to file data/human_lung/magma_scores/lung-COVID19.genes.raw\n",
      "\n",
      "\n",
      "End time is 10:27:07, Monday 08 Apr 2024 (elapsed: 00:09:07)\n",
      "Welcome to MAGMA v1.10 (custom)\n",
      "Using flags:\n",
      "\t--bfile data/all_hg38\n",
      "\t--gene-annot data/magma_0kb.genes.annot\n",
      "\t--pval data_covid/COVID19_GWAS_summary_stats.txt use=13,9 ncol=11\n",
      "\t--gene-model snp-wise=mean\n",
      "\t--out data/human_pbmc/magma_scores/pbmc-COVID19\n",
      "\n",
      "Start time is 10:27:07, Monday 08 Apr 2024\n",
      "\n",
      "Loading PLINK-format data...\n",
      "Reading file data/all_hg38.fam... 3202 individuals read\n",
      "Reading file data/all_hg38.bim... 70883903 SNPs read\n",
      "\tWARNING: file contains 1868379 duplicate SNP IDs; writing list of IDs to supplementary log file\n",
      "Preparing file data/all_hg38.bed... \n",
      "\n",
      "Reading SNP p-values from file data_covid/COVID19_GWAS_summary_stats.txt... \n",
      "\tdetected 13 variables in file\n",
      "\tusing variable: variable 13 (SNP id)\n",
      "\tusing variable: variable 9 (p-value)\n",
      "\tusing variable: variable 11 (sample size; discarding SNPs with N < 50)\n",
      "\tread 84817347 lines from file, containing valid SNP p-values for 2588143 SNPs in data (3.051% of lines, 3.454% of SNPs in data)\n",
      "\tWARNING: file contained 10806072 SNP IDs with duplications\n",
      "\t         dropped all occurrences of each from analysis\n",
      "\t         writing list of duplicated IDs to supplementary log file\n",
      "Loading gene annotation from file data/magma_0kb.genes.annot... \n",
      "\t18223 gene definitions read from file\n",
      "\tfound 9731 genes containing valid SNPs in genotype data\n",
      "\n",
      "\n",
      "Starting gene analysis... \n",
      "\tusing model: SNPwise-mean\n",
      "\tWARNING: analysis failed for gene ENSG00000185940; gene contains no valid SNPs after internal QC\n",
      "\twriting gene analysis results to file data/human_pbmc/magma_scores/pbmc-COVID19.genes.out                         \n",
      "\twriting intermediate output to file data/human_pbmc/magma_scores/pbmc-COVID19.genes.raw\n",
      "\n",
      "\n",
      "End time is 10:36:24, Monday 08 Apr 2024 (elapsed: 00:09:17)\n",
      "Magma score calculation completed\n"
     ]
    }
   ],
   "source": [
    "# Calling Pops1 step\n",
    "!cp ../runPopsi1.sh .\n",
    "!bash runPopsi1.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a0a5397-f774-4565-856a-c16db7d9c53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Pops for COVID19 GWAS summary statistic file...\n",
      "Pops COVID19 pipeline completed\n"
     ]
    }
   ],
   "source": [
    "# Calling Pops2 step\n",
    "!cp ../runPopsi2.sh .\n",
    "!bash runPopsi2.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
