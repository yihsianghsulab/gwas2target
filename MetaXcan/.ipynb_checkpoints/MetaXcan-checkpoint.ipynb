{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cecaca4a-bd04-4bd2-ab60-0a36b34331c1",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "Please ensure the **MetaXcan repo** and **\"imlabtools\" env** are installed through the **terminal** before starting.<br>\n",
    "Or open your terminal and install using the following commands:<br>\n",
    "\n",
    "<h3>Clone the MetaXcan repo</h3>\n",
    "<pre><code>git clone https://github.com/hakyimlab/MetaXcan\n",
    "</code></pre>\n",
    "\n",
    "<h3>Change directory</h3>\n",
    "<pre><code>cd MetaXcan/software\n",
    "</code></pre>\n",
    "\n",
    "<h3>Install imlabtools Conda Environment and Load</h3>\n",
    "<pre><code>conda activate base\n",
    "conda env create -f /path/to/this/repo/software/conda_env.yaml\n",
    "conda activate imlabtools\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a4186-54fe-4f2d-bb14-273334e6db6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab560c06-279f-4823-82a1-42ff945246dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading COVID19_HGI_A1_ALL_20201020.txt.gz...Downloading COVID19_HGI_A2_ALL_leave_23andme_20201020.txt.gz...\n",
      "\n",
      "Downloading COVID19_HGI_B1_ALL_20201020.txt.gz...\n",
      "Downloading COVID19_HGI_B2_ALL_leave_23andme_20201020.txt.gz...\n",
      "Downloaded COVID19_HGI_A1_ALL_20201020.txt.gz successfully.\n",
      "Processing COVID19_HGI_A1_ALL_20201020.txt.gz...\n",
      "Downloaded COVID19_HGI_A2_ALL_leave_23andme_20201020.txt.gz successfully.\n",
      "Processing COVID19_HGI_A2_ALL_leave_23andme_20201020.txt.gz...\n",
      "Downloaded COVID19_HGI_B1_ALL_20201020.txt.gz successfully.\n",
      "Processing COVID19_HGI_B1_ALL_20201020.txt.gz...\n",
      "Downloaded COVID19_HGI_B2_ALL_leave_23andme_20201020.txt.gz successfully.\n",
      "Processing COVID19_HGI_B2_ALL_leave_23andme_20201020.txt.gz...\n",
      "Completed processing for COVID19_HGI_A1_ALL_20201020.txt.gz.\n",
      "Downloading COVID19_HGI_C1_ALL_leave_23andme_20201020.txt.gz...\n",
      "Downloaded COVID19_HGI_C1_ALL_leave_23andme_20201020.txt.gz successfully.\n",
      "Processing COVID19_HGI_C1_ALL_leave_23andme_20201020.txt.gz...\n",
      "Completed processing for COVID19_HGI_B2_ALL_leave_23andme_20201020.txt.gz.\n",
      "Downloading COVID19_HGI_C2_ALL_leave_23andme_20201020.txt.gz...\n",
      "Downloaded COVID19_HGI_C2_ALL_leave_23andme_20201020.txt.gz successfully.\n",
      "Processing COVID19_HGI_C2_ALL_leave_23andme_20201020.txt.gz...\n",
      "Completed processing for COVID19_HGI_A2_ALL_leave_23andme_20201020.txt.gz.\n",
      "Downloading COVID19_HGI_D1_ALL_20201020.txt.gz...\n",
      "Downloaded COVID19_HGI_D1_ALL_20201020.txt.gz successfully.\n",
      "Processing COVID19_HGI_D1_ALL_20201020.txt.gz...\n",
      "Completed processing for COVID19_HGI_B1_ALL_20201020.txt.gz.\n",
      "Completed processing for COVID19_HGI_C1_ALL_leave_23andme_20201020.txt.gz.\n",
      "Completed processing for COVID19_HGI_D1_ALL_20201020.txt.gz.\n",
      "Completed processing for COVID19_HGI_C2_ALL_leave_23andme_20201020.txt.gz.\n",
      "Downloading mashr_eqtl.tar...\n",
      "Downloading gtex_v8_expression_mashr_snp_smultixcan_covariance.txt.gz...\n",
      "Downloaded gtex_v8_expression_mashr_snp_smultixcan_covariance.txt.gz successfully.\n",
      "Downloaded mashr_eqtl.tar successfully.\n",
      "Extracting mashr_eqtl.tar...\n",
      "Completed extracting mashr_eqtl.tar.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "import shutil\n",
    "import tarfile\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Initialize a session for HTTP requests\n",
    "session = requests.Session()\n",
    "\n",
    "# Download and preprocess GWAS data\n",
    "def download_and_process(url, download_dir):\n",
    "    filename = os.path.basename(url)\n",
    "    filepath = os.path.join(download_dir, filename)\n",
    "    temp_file = filepath.rstrip('.gz')\n",
    "    \n",
    "    # Stream download file if it does not exist\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        with session.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(filepath, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        print(f\"Downloaded {filename} successfully.\")\n",
    "    \n",
    "    # Process the file\n",
    "    print(f\"Processing {filename}...\")\n",
    "    with gzip.open(filepath, 'rt') as f_in, open(temp_file, 'w') as f_out:\n",
    "        first_line = True\n",
    "        for line in f_in:\n",
    "            if first_line:\n",
    "                f_out.write(line)\n",
    "                first_line = False\n",
    "            else:\n",
    "                parts = line.split('\\t')\n",
    "                snp_info = parts[4].split(':')\n",
    "                parts[4] = f\"chr{snp_info[0]}_{snp_info[1]}_{snp_info[2]}_{snp_info[3]}_b38\"\n",
    "                f_out.write('\\t'.join(parts))\n",
    "                \n",
    "    # Compress the processed file back\n",
    "    with open(temp_file, 'rb') as f_in, gzip.open(filepath, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "    os.remove(temp_file)\n",
    "    print(f\"Completed processing for {filename}.\")\n",
    "\n",
    "# Download tissue models\n",
    "def download_models(url, download_dir):\n",
    "    filename = os.path.basename(url)\n",
    "    filepath = os.path.join(download_dir, filename)\n",
    "    \n",
    "    # Stream download file if it does not exist\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        with session.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(filepath, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        print(f\"Downloaded {filename} successfully.\")\n",
    "    \n",
    "    # Extract if it's a tar file\n",
    "    if filepath.endswith('.tar'):\n",
    "        print(f\"Extracting {filename}...\")\n",
    "        with tarfile.open(filepath) as tar:\n",
    "            tar.extractall(path=download_dir)\n",
    "        print(f\"Completed extracting {filename}.\")\n",
    "\n",
    "# Define directories and URLs\n",
    "base_dir = 'MetaXcan/software'\n",
    "data_dir = os.path.join(base_dir, \"data_covid\")\n",
    "model_dir = os.path.join(base_dir, \"predi_models\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "data_urls = [\n",
    "\"https://storage.googleapis.com/covid19-hg-public/20200915/results/20201020/COVID19_HGI_A1_ALL_20201020.txt.gz\",\n",
    "\"https://storage.googleapis.com/covid19-hg-public/20200915/results/20201020/COVID19_HGI_A2_ALL_leave_23andme_20201020.txt.gz\",\n",
    "\"https://storage.googleapis.com/covid19-hg-public/20200915/results/20201020/COVID19_HGI_B1_ALL_20201020.txt.gz\",\n",
    "\"https://storage.googleapis.com/covid19-hg-public/20200915/results/20201020/COVID19_HGI_B2_ALL_leave_23andme_20201020.txt.gz\",\n",
    "\"https://storage.googleapis.com/covid19-hg-public/20200915/results/20201020/COVID19_HGI_C1_ALL_leave_23andme_20201020.txt.gz\",\n",
    "\"https://storage.googleapis.com/covid19-hg-public/20200915/results/20201020/COVID19_HGI_C2_ALL_leave_23andme_20201020.txt.gz\",\n",
    "\"https://storage.googleapis.com/covid19-hg-public/20200915/results/20201020/COVID19_HGI_D1_ALL_20201020.txt.gz\"\n",
    "]\n",
    "\n",
    "model_urls = [\n",
    "\"https://zenodo.org/record/3518299/files/mashr_eqtl.tar\",\n",
    "\"https://zenodo.org/record/3518299/files/gtex_v8_expression_mashr_snp_smultixcan_covariance.txt.gz\"\n",
    "]\n",
    "\n",
    "# Parallel processing with four worker nodes in max\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    executor.map(lambda x: download_and_process(*x), [(url, data_dir) for url in data_urls])\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    executor.map(lambda x: download_models(*x), [(url, model_dir) for url in model_urls])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac9a8bd",
   "metadata": {},
   "source": [
    "## Run MetaXcan pipeline\n",
    "Please ensure the **ipykernel** and **notebook** existed, and install the **imlabtools** environment to the ipykernel via the following commands in **terminal**:<br>\n",
    "<pre><code>\n",
    "!pip install notebook\n",
    "!pip install ipykernel\n",
    "!python -m ipykernel install --user --name=imlabtools</code></pre>\n",
    "\n",
    "Then, open your juypter notebook again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eefb7208-a9e0-4c04-81a0-11c1a2fd08db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SPrediXcan for Lung with COVID19_HGI_A1_ALL_20201020.txt.gz...\n",
      "INFO - MetaXcan/software/output/spredixcan/COVID19_HGI_A1_ALL_20201020__PM__Lung.csv already exists, move it or delete it if you want it done again\n",
      "SPrediXcan processing completed for COVID19_HGI_A1_ALL_20201020.txt.gz and tissue Lung.\n",
      "Running SPrediXcan for Whole_Blood with COVID19_HGI_A1_ALL_20201020.txt.gz...\n",
      "INFO - MetaXcan/software/output/spredixcan/COVID19_HGI_A1_ALL_20201020__PM__Whole_Blood.csv already exists, move it or delete it if you want it done again\n",
      "SPrediXcan processing completed for COVID19_HGI_A1_ALL_20201020.txt.gz and tissue Whole_Blood.\n",
      "Running SPrediXcan for Lung with COVID19_HGI_A2_ALL_leave_23andme_20201020.txt.gz...\n",
      "INFO - MetaXcan/software/output/spredixcan/COVID19_HGI_A2_ALL_leave_23andme_20201020__PM__Lung.csv already exists, move it or delete it if you want it done again\n",
      "SPrediXcan processing completed for COVID19_HGI_A2_ALL_leave_23andme_20201020.txt.gz and tissue Lung.\n",
      "Running SPrediXcan for Whole_Blood with COVID19_HGI_A2_ALL_leave_23andme_20201020.txt.gz...\n",
      "INFO - MetaXcan/software/output/spredixcan/COVID19_HGI_A2_ALL_leave_23andme_20201020__PM__Whole_Blood.csv already exists, move it or delete it if you want it done again\n",
      "SPrediXcan processing completed for COVID19_HGI_A2_ALL_leave_23andme_20201020.txt.gz and tissue Whole_Blood.\n",
      "Running SPrediXcan for Lung with COVID19_HGI_B1_ALL_20201020.txt.gz...\n",
      "INFO - MetaXcan/software/output/spredixcan/COVID19_HGI_B1_ALL_20201020__PM__Lung.csv already exists, move it or delete it if you want it done again\n",
      "SPrediXcan processing completed for COVID19_HGI_B1_ALL_20201020.txt.gz and tissue Lung.\n",
      "Running SPrediXcan for Whole_Blood with COVID19_HGI_B1_ALL_20201020.txt.gz...\n",
      "INFO - MetaXcan/software/output/spredixcan/COVID19_HGI_B1_ALL_20201020__PM__Whole_Blood.csv already exists, move it or delete it if you want it done again\n",
      "SPrediXcan processing completed for COVID19_HGI_B1_ALL_20201020.txt.gz and tissue Whole_Blood.\n",
      "Running SPrediXcan for Lung with COVID19_HGI_B2_ALL_leave_23andme_20201020.txt.gz...\n",
      "INFO - MetaXcan/software/output/spredixcan/COVID19_HGI_B2_ALL_leave_23andme_20201020__PM__Lung.csv already exists, move it or delete it if you want it done again\n",
      "SPrediXcan processing completed for COVID19_HGI_B2_ALL_leave_23andme_20201020.txt.gz and tissue Lung.\n",
      "Running SPrediXcan for Whole_Blood with COVID19_HGI_B2_ALL_leave_23andme_20201020.txt.gz...\n",
      "INFO - MetaXcan/software/output/spredixcan/COVID19_HGI_B2_ALL_leave_23andme_20201020__PM__Whole_Blood.csv already exists, move it or delete it if you want it done again\n",
      "SPrediXcan processing completed for COVID19_HGI_B2_ALL_leave_23andme_20201020.txt.gz and tissue Whole_Blood.\n",
      "Running SPrediXcan for Lung with COVID19_HGI_C1_ALL_leave_23andme_20201020.txt.gz...\n",
      "INFO - MetaXcan/software/output/spredixcan/COVID19_HGI_C1_ALL_leave_23andme_20201020__PM__Lung.csv already exists, move it or delete it if you want it done again\n",
      "SPrediXcan processing completed for COVID19_HGI_C1_ALL_leave_23andme_20201020.txt.gz and tissue Lung.\n",
      "Running SPrediXcan for Whole_Blood with COVID19_HGI_C1_ALL_leave_23andme_20201020.txt.gz...\n",
      "INFO - MetaXcan/software/output/spredixcan/COVID19_HGI_C1_ALL_leave_23andme_20201020__PM__Whole_Blood.csv already exists, move it or delete it if you want it done again\n",
      "SPrediXcan processing completed for COVID19_HGI_C1_ALL_leave_23andme_20201020.txt.gz and tissue Whole_Blood.\n",
      "Running SPrediXcan for Lung with COVID19_HGI_C2_ALL_leave_23andme_20201020.txt.gz...\n",
      "INFO - MetaXcan/software/output/spredixcan/COVID19_HGI_C2_ALL_leave_23andme_20201020__PM__Lung.csv already exists, move it or delete it if you want it done again\n",
      "SPrediXcan processing completed for COVID19_HGI_C2_ALL_leave_23andme_20201020.txt.gz and tissue Lung.\n",
      "Running SPrediXcan for Whole_Blood with COVID19_HGI_C2_ALL_leave_23andme_20201020.txt.gz...\n",
      "INFO - MetaXcan/software/output/spredixcan/COVID19_HGI_C2_ALL_leave_23andme_20201020__PM__Whole_Blood.csv already exists, move it or delete it if you want it done again\n",
      "SPrediXcan processing completed for COVID19_HGI_C2_ALL_leave_23andme_20201020.txt.gz and tissue Whole_Blood.\n",
      "Running SPrediXcan for Lung with COVID19_HGI_D1_ALL_20201020.txt.gz...\n",
      "INFO - MetaXcan/software/output/spredixcan/COVID19_HGI_D1_ALL_20201020__PM__Lung.csv already exists, move it or delete it if you want it done again\n",
      "SPrediXcan processing completed for COVID19_HGI_D1_ALL_20201020.txt.gz and tissue Lung.\n",
      "Running SPrediXcan for Whole_Blood with COVID19_HGI_D1_ALL_20201020.txt.gz...\n",
      "INFO - MetaXcan/software/output/spredixcan/COVID19_HGI_D1_ALL_20201020__PM__Whole_Blood.csv already exists, move it or delete it if you want it done again\n",
      "SPrediXcan processing completed for COVID19_HGI_D1_ALL_20201020.txt.gz and tissue Whole_Blood.\n"
     ]
    }
   ],
   "source": [
    "# Calling runSPrediXcan.sh\n",
    "!bash runSPrediXcan.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8236d46-296d-4595-930c-de2dc91d5b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading mashr_eqtl.tar...\n",
      "Extracting mashr_eqtl.tar...\n",
      "Completed extracting mashr_eqtl.tar.\n",
      "Downloading gtex_v8_expression_mashr_snp_smultixcan_covariance.txt.gz...\n"
     ]
    }
   ],
   "source": [
    "# Calling runSMultiXcan.sh\n",
    "!bash runSMultiXcan.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67937388-5b8b-494b-972b-8033b0d53c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imlabtools",
   "language": "python",
   "name": "imlabtools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
